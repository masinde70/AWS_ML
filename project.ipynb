{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Bike Sharing Demand with AutoGluon Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Notebook should be using a `ml.t3.medium` instance (2 vCPU + 4 GiB)\n",
    "2. Notebook should be using kernal: `Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U pip\n",
    "#!pip install -U setuptools wheel\n",
    "#!pip install -U \"mxnet<2.0.0\" bokeh==2.0.1\n",
    "#!pip install autogluon --no-cache-dir\n",
    "#!pip install kaggle\n",
    "# Without --no-cache-dir, smaller aws instances may have trouble installing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Kaggle API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the .kaggle directory and an empty kaggle.json file\n",
    "!mkdir -p /root/.kaggle\n",
    "!touch /root/.kaggle/kaggle.json\n",
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in your user name and key from creating the kaggle account and API token file\n",
    "import json\n",
    "kaggle_username = \"masinde\"\n",
    "kaggle_key = \"26ba6a9b0bd0c324054f61b2158b9a7a\"\n",
    "\n",
    "# Save API token the kaggle.json file\n",
    "with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
    "    f.write(json.dumps({\"username\": kaggle_username, \"key\": kaggle_key}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bike-sharing-demand.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "Archive:  bike-sharing-demand.zip\n",
      "  inflating: sampleSubmission.csv    \n",
      "  inflating: test.csv                \n",
      "  inflating: train.csv               \n"
     ]
    }
   ],
   "source": [
    "# Download the dataset, it will be in a .zip file so you'll need to unzip it as well.\n",
    "!kaggle competitions download -c bike-sharing-demand\n",
    "# If you already downloaded it you can use the -o command to overwrite the file\n",
    "!unzip -o bike-sharing-demand.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor  \n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
       "0 2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "1 2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "2 2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
       "3 2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
       "4 2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
       "\n",
       "   humidity  windspeed  casual  registered  count  \n",
       "0        81        0.0       3          13     16  \n",
       "1        80        0.0       8          32     40  \n",
       "2        80        0.0       5          27     32  \n",
       "3        75        0.0       3          10     13  \n",
       "4        75        0.0       0           1      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the train dataset in pandas by reading the csv\n",
    "# Set the parsing of the datetime column so you can use some of the `dt` features in pandas later\n",
    "train = pd.read_csv('train.csv', parse_dates=['datetime'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10886 entries, 0 to 10885\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   datetime    10886 non-null  datetime64[ns]\n",
      " 1   season      10886 non-null  int64         \n",
      " 2   holiday     10886 non-null  int64         \n",
      " 3   workingday  10886 non-null  int64         \n",
      " 4   weather     10886 non-null  int64         \n",
      " 5   temp        10886 non-null  float64       \n",
      " 6   atemp       10886 non-null  float64       \n",
      " 7   humidity    10886 non-null  int64         \n",
      " 8   windspeed   10886 non-null  float64       \n",
      " 9   casual      10886 non-null  int64         \n",
      " 10  registered  10886 non-null  int64         \n",
      " 11  count       10886 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(3), int64(8)\n",
      "memory usage: 1020.7 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>2.506614</td>\n",
       "      <td>1.116174</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>4.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holiday</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.166599</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workingday</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>0.680875</td>\n",
       "      <td>0.466159</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>1.418427</td>\n",
       "      <td>0.633839</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>4.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>20.230860</td>\n",
       "      <td>7.791590</td>\n",
       "      <td>0.82</td>\n",
       "      <td>13.9400</td>\n",
       "      <td>20.500</td>\n",
       "      <td>26.2400</td>\n",
       "      <td>41.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atemp</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>23.655084</td>\n",
       "      <td>8.474601</td>\n",
       "      <td>0.76</td>\n",
       "      <td>16.6650</td>\n",
       "      <td>24.240</td>\n",
       "      <td>31.0600</td>\n",
       "      <td>45.4550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>61.886460</td>\n",
       "      <td>19.245033</td>\n",
       "      <td>0.00</td>\n",
       "      <td>47.0000</td>\n",
       "      <td>62.000</td>\n",
       "      <td>77.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windspeed</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>12.799395</td>\n",
       "      <td>8.164537</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.0015</td>\n",
       "      <td>12.998</td>\n",
       "      <td>16.9979</td>\n",
       "      <td>56.9969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casual</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>36.021955</td>\n",
       "      <td>49.960477</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>49.0000</td>\n",
       "      <td>367.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>registered</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>155.552177</td>\n",
       "      <td>151.039033</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>118.000</td>\n",
       "      <td>222.0000</td>\n",
       "      <td>886.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>191.574132</td>\n",
       "      <td>181.144454</td>\n",
       "      <td>1.00</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>145.000</td>\n",
       "      <td>284.0000</td>\n",
       "      <td>977.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count        mean         std   min      25%      50%       75%  \\\n",
       "season      10886.0    2.506614    1.116174  1.00   2.0000    3.000    4.0000   \n",
       "holiday     10886.0    0.028569    0.166599  0.00   0.0000    0.000    0.0000   \n",
       "workingday  10886.0    0.680875    0.466159  0.00   0.0000    1.000    1.0000   \n",
       "weather     10886.0    1.418427    0.633839  1.00   1.0000    1.000    2.0000   \n",
       "temp        10886.0   20.230860    7.791590  0.82  13.9400   20.500   26.2400   \n",
       "atemp       10886.0   23.655084    8.474601  0.76  16.6650   24.240   31.0600   \n",
       "humidity    10886.0   61.886460   19.245033  0.00  47.0000   62.000   77.0000   \n",
       "windspeed   10886.0   12.799395    8.164537  0.00   7.0015   12.998   16.9979   \n",
       "casual      10886.0   36.021955   49.960477  0.00   4.0000   17.000   49.0000   \n",
       "registered  10886.0  155.552177  151.039033  0.00  36.0000  118.000  222.0000   \n",
       "count       10886.0  191.574132  181.144454  1.00  42.0000  145.000  284.0000   \n",
       "\n",
       "                 max  \n",
       "season        4.0000  \n",
       "holiday       1.0000  \n",
       "workingday    1.0000  \n",
       "weather       4.0000  \n",
       "temp         41.0000  \n",
       "atemp        45.4550  \n",
       "humidity    100.0000  \n",
       "windspeed    56.9969  \n",
       "casual      367.0000  \n",
       "registered  886.0000  \n",
       "count       977.0000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple output of the train dataset to view some of the min/max/varition of the dataset features.\n",
    "train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-20 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.365</td>\n",
       "      <td>56</td>\n",
       "      <td>26.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-20 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-20 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-20 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-20 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  season  holiday  workingday  weather   temp   atemp  \\\n",
       "0 2011-01-20 00:00:00       1        0           1        1  10.66  11.365   \n",
       "1 2011-01-20 01:00:00       1        0           1        1  10.66  13.635   \n",
       "2 2011-01-20 02:00:00       1        0           1        1  10.66  13.635   \n",
       "3 2011-01-20 03:00:00       1        0           1        1  10.66  12.880   \n",
       "4 2011-01-20 04:00:00       1        0           1        1  10.66  12.880   \n",
       "\n",
       "   humidity  windspeed  \n",
       "0        56    26.0027  \n",
       "1        56     0.0000  \n",
       "2        56     0.0000  \n",
       "3        56    11.0014  \n",
       "4        56    11.0014  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the test pandas dataframe in pandas by reading the csv, remember to parse the datetime!\n",
    "test = pd.read_csv('test.csv',  parse_dates=['datetime'])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-20 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-20 01:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-20 02:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-20 03:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-20 04:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  count\n",
       "0  2011-01-20 00:00:00      0\n",
       "1  2011-01-20 01:00:00      0\n",
       "2  2011-01-20 02:00:00      0\n",
       "3  2011-01-20 03:00:00      0\n",
       "4  2011-01-20 04:00:00      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same thing as train and test dataset\n",
    "submission = pd.read_csv('sampleSubmission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train a model using AutoGluonâ€™s Tabular Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements:\n",
    "* We are predicting `count`, so it is the label we are setting.\n",
    "* Ignore `casual` and `registered` columns as they are also not present in the test dataset. \n",
    "* Use the `root_mean_squared_error` as the metric to use for evaluation.\n",
    "* Set a time limit of 10 minutes (600 seconds).\n",
    "* Use the preset `best_quality` to focus on creating the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20230106_104653/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 600s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20230106_104653/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.8.10\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Oct 26 20:36:53 UTC 2022\n",
      "Train Data Rows:    10886\n",
      "Train Data Columns: 11\n",
      "Label Column: count\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Dropping user-specified ignored columns: ['casual', 'registered']\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3105.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.78 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "/usr/local/lib/python3.8/dist-packages/autogluon/features/generators/datetime.py:59: FutureWarning: casting datetime64[ns, UTC] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
      "  good_rows = series[~series.isin(bad_rows)].astype(np.int64)\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', []) : 1 | ['datetime']\n",
      "\t\t('float', [])    : 3 | ['temp', 'atemp', 'windspeed']\n",
      "\t\t('int', [])      : 5 | ['season', 'holiday', 'workingday', 'weather', 'humidity']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
      "\t\t('int', [])                  : 3 | ['season', 'weather', 'humidity']\n",
      "\t\t('int', ['bool'])            : 2 | ['holiday', 'workingday']\n",
      "\t\t('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
      "\t0.2s = Fit runtime\n",
      "\t9 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.98 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.71s of the 599.71s of remaining time.\n",
      "\t-101.5462\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 397.37s of the 597.37s of remaining time.\n",
      "\t-84.1251\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 397.19s of the 597.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-131.4609\t = Validation score   (-root_mean_squared_error)\n",
      "\t58.29s\t = Training   runtime\n",
      "\t6.93s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 330.07s of the 530.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-131.0542\t = Validation score   (-root_mean_squared_error)\n",
      "\t25.28s\t = Training   runtime\n",
      "\t1.35s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 301.03s of the 501.03s of remaining time.\n",
      "\t-116.5443\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.04s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 287.89s of the 487.9s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-130.4788\t = Validation score   (-root_mean_squared_error)\n",
      "\t190.75s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 94.19s of the 294.19s of remaining time.\n",
      "\t-124.5881\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.66s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 86.5s of the 286.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-136.1061\t = Validation score   (-root_mean_squared_error)\n",
      "\t85.77s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 196.46s of remaining time.\n",
      "\t-84.1251\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 195.99s of the 195.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-60.4599\t = Validation score   (-root_mean_squared_error)\n",
      "\t47.16s\t = Training   runtime\n",
      "\t3.22s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 144.93s of the 144.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-55.1578\t = Validation score   (-root_mean_squared_error)\n",
      "\t21.0s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 120.28s of the 120.27s of remaining time.\n",
      "\t-53.359\t = Validation score   (-root_mean_squared_error)\n",
      "\t25.14s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 92.2s of the 92.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=\"count\", \n",
    "                             eval_metric='root_mean_squared_error',\n",
    "                             problem_type='regression',\n",
    "                             learner_kwargs={'ignored_columns': ['casual','registered']}\n",
    "                            ).fit(train_data=train,\n",
    "                                  time_limit=600,\n",
    "                                  presets=\"best_quality\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review AutoGluon's training run with ranking of models that did the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.fit_summary(show_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create predictions from test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(test)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: Kaggle will reject the submission if we don't set everything to be > 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the `predictions` series to see if there are any negative values\n",
    "predictions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many negative values do we have?\n",
    "predictions.lt(0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set them to zero\n",
    "predictions.iloc[predictions<0] = 0\n",
    "predictions.lt(0).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set predictions to submission dataframe, save, and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"count\"] = predictions\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c bike-sharing-demand -f submission.csv -m \"first raw submission\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View submission via the command line or in the web browser under the competition's page - `My Submissions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submissions -c bike-sharing-demand | tail -n +1 | head -n 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial score of 1.80370"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Exploratory Data Analysis and Creating an additional feature\n",
    "* Any additional feature will do, but a great suggestion would be to separate out the datetime into hour, day, or month parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of all features to show the distribution of each one relative to the data. This is part of the exploritory data analysis\n",
    "train.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Distributions of registered vs casual rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distributions of registered vs casual rides\n",
    "sns.histplot(train['registered'], label='registered')\n",
    "sns.histplot(train['casual'], label='casual')\n",
    "plt.legend()\n",
    "plt.xlabel('rides')\n",
    "plt.title(\"Rides distributions\")\n",
    "plt.savefig('rides_distributions.png', format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The registered users perform way more rides than casual ones. Furthermore, we can see that the two distributions are skewed to the right, meaning that, for most of the entries in the data, zero or a small number of rides. Finally, every entry in the data has quite a large number of rides (that is, higher than 800)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make category types for these so models know they are not just numbers\n",
    "* AutoGluon originally sees these as ints, but in reality they are int representations of a category.\n",
    "* Setting the dtype to category will classify these as categories in AutoGluon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"season\"] = train[\"season\"].astype(\"category\")\n",
    "train[\"weather\"] = train[\"weather\"].astype(\"category\")\n",
    "test[\"season\"] = test[\"season\"].astype(\"category\")\n",
    "test[\"weather\"] = test[\"weather\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new feature\n",
    "train['year'] = train.datetime.dt.year\n",
    "train['month'] = train.datetime.dt.month\n",
    "train['day'] = train.datetime.dt.day\n",
    "train['hour'] = train.datetime.dt.hour\n",
    "train.drop([\"datetime\"], axis=1, inplace=True)\n",
    "\n",
    "test['year'] = test.datetime.dt.year\n",
    "test['month'] = test.datetime.dt.month\n",
    "test['day'] = test.datetime.dt.day\n",
    "test['hour'] = test.datetime.dt.hour\n",
    "test.drop([\"datetime\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "figure, axes = plt.subplots(nrows=2, ncols=2) #\n",
    "plt.tight_layout()\n",
    "figure.set_size_inches(10, 10)\n",
    "\n",
    "\n",
    "sns.boxplot(x='season', y='count', data=train, ax=axes[0, 0])\n",
    "sns.boxplot(x='weather', y='count', data=train, ax=axes[0, 1])\n",
    "sns.boxplot(x='holiday', y='count', data=train, ax=axes[1, 0])\n",
    "sns.boxplot(x='workingday', y='count', data=train, ax=axes[1, 1])\n",
    "\n",
    "\n",
    "axes[0, 0].set(title='Box Plot On Count Across Season')\n",
    "axes[0, 1].set(title='Box Plot On Count Across Weather')\n",
    "axes[1, 0].set(title='Box Plot On Count Across Holiday')\n",
    "axes[1, 1].set(title='Box Plot On Count Across Working Day')\n",
    "\n",
    "\n",
    "axes[0, 1].tick_params('x', labelrotation=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['season'] = train['season'].map({1: 'Spring', \n",
    "                                       2: 'Summer', \n",
    "                                       3: 'Fall', \n",
    "                                       4: 'Winter' })\n",
    "train['weather'] = train['weather'].map({1: 'Clear', \n",
    "                                         2: 'Mist, Few clouds', \n",
    "                                         3: 'Light Snow, Rain, Thunder', \n",
    "                                         4: 'Heavy Snow, Rain, Thunder'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "sns.pointplot(data=train, x='hour', y='registered', hue='workingday', ax=ax)\n",
    "ax.set(title='Count of bikes during working days: Registered users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "sns.pointplot(data=train, x='hour', y='count',  hue='holiday', ax=ax)\n",
    "ax.set(title='Count of bikes during holidays days: Registered users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "sns.pointplot(data=train, x='hour', y='count',  hue='season', ax=ax)\n",
    "ax.set(title='Count of bikes during different seasons : Registered users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "sns.pointplot(data=train, x='hour', y='count',  hue='weather', ax=ax)\n",
    "ax.set(title='Count of bikes in different weather: Registered users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_correlations(data, col):\n",
    "    # get correlation between col and registered rides\n",
    "    corr_r = np.corrcoef(data[col], data[\"registered\"])[0,1]\n",
    "    ax =sns.regplot(x=col, y='registered', data=data,scatter_kws={'alpha':0.05},label=f'Registered rides(correlation:{corr_r:.3f})')\n",
    "    # get correlation between col and casual rides\n",
    "    corr_c = np.corrcoef(data[col], data[\"casual\"])[0,1]\n",
    "    ax = sns.regplot(x=col, y='casual',data=data,scatter_kws={'alpha':0.05},label=f'Casual rides (correlation:{corr_c:.3f})')\n",
    "    #adjust legend alpha\n",
    "    legend = ax.legend()\n",
    "    for lh in legend.legendHandles:\n",
    "        lh.set_alpha(0.5)\n",
    "    ax.set_ylabel(\"rides\")\n",
    "    ax.set_title(f\"Correlation between rides and {col}\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between rides and temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "ax = plot_correlations(train, 'temp')\n",
    "plt.savefig('correlation_temp.png', format='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "ax = plot_correlations(train, 'atemp')\n",
    "plt.savefig('correlation_atemp.png', format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher temperatures have a positive impact on the number of rides (the correlation between registered/casual rides and temp is 0.31 and 0.46, respectively, and it's a similar case for atemp). Note that as the values in the registered column are widely spread with respect to the different values in temp, we have a lower correlation compared to the casual column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between rides and humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "ax = plot_correlations(train, 'humidity')\n",
    "plt.savefig('correlation_hum.png', format='png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The humidity level has a negative correlation with both types of rides (-0.265 for registered and -0.348 for casual). This means that with a high level of humidity (mist or rain), customers will tend not to use the bike sharing service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between the number of rides and the wind speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "ax = plot_correlations(train, 'windspeed')\n",
    "plt.savefig('correlation_windspeed.png', format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is minimal correlation between the number of rides and the wind speed ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix Plot\n",
    "A comparison between different continuous features is  to use the correlation matrix plot. It allows us to quickly visualize any possible relationships between the different features and identify potential clusters with highly correlated features.\n",
    "\n",
    "With the training data we will visualize the temperature, atemp, humidity, windspeed, registered and casual columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot correlation matrix\n",
    "cols = [\"temp\", \"atemp\", \"humidity\", \"windspeed\", \"registered\", \"casual\"]\n",
    "plot_data = train[cols]\n",
    "corr = plot_data.corr()\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.matshow(corr, fignum=fig.number)\n",
    "plt.xticks(range(len(plot_data.columns)), plot_data.columns)\n",
    "plt.yticks(range(len(plot_data.columns)), plot_data.columns)\n",
    "plt.colorbar()\n",
    "plt.ylim([5.5, -0.5])\n",
    "fig.savefig('correlations.png', format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The conclusion of the visualization is that when the temperature is good the hire of the bike is good for both registered users and casual users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Rerun the model with the same settings as before, just with more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_new_features = TabularPredictor(label=\"count\", \n",
    "                             eval_metric='root_mean_squared_error',\n",
    "                             problem_type='regression',\n",
    "                             learner_kwargs={'ignored_columns': ['casual','registered']}\n",
    "                            ).fit(train_data=train,\n",
    "                                  time_limit=600,\n",
    "                                  presets=\"best_quality\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_new_features.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to set all negative values to zero\n",
    "predictions_new_features = predictor_new_features.predict(test)\n",
    "predictions_new_features.iloc[predictions_new_features.lt(0)] = 0\n",
    "\n",
    "predictions_new_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same submitting predictions\n",
    "submission_new_features = pd.read_csv('sampleSubmission.csv', parse_dates=[\"datetime\"])\n",
    "submission_new_features[\"count\"] = predictions_new_features\n",
    "submission_new_features.to_csv(\"submission_new_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c bike-sharing-demand -f submission_new_features.csv -m \"new features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submissions -c bike-sharing-demand | tail -n +1 | head -n 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Score of 0.47052\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Hyper parameter optimization\n",
    "* There are many options for hyper parameter optimization.\n",
    "* Options are to change the AutoGluon higher level parameters or the individual model hyperparameters.\n",
    "* The hyperparameters of the models themselves that are in AutoGluon. Those need the `hyperparameter` and `hyperparameter_tune_kwargs` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 5\n",
    "search_strategy = 'auto'\n",
    "hyperparameters = {\n",
    "  'NN_TORCH': {'num_epochs': 10, 'batch_size': 32}, \n",
    "  'GBM': {'num_boost_round': 20}\n",
    "}\n",
    "hyperparameter_tune_kwargs = { \n",
    "  'num_trials': num_trials,\n",
    "  'scheduler' : 'local',\n",
    "  'searcher': search_strategy,\n",
    "}\n",
    "\n",
    "\n",
    "predictor_new_hpo = TabularPredictor(label=\"count\", \n",
    "                             eval_metric='root_mean_squared_error',\n",
    "                             problem_type='regression',\n",
    "                             learner_kwargs={'ignored_columns': ['casual','registered']}\n",
    "                            ).fit(train_data=train,\n",
    "                                  num_bag_folds=5,\n",
    "                                  num_bag_sets=1,\n",
    "                                  num_stack_levels=1,\n",
    "                                  time_limit=600,\n",
    "                                  presets=\"best_quality\",\n",
    "                                  hyperparameters=hyperparameters,\n",
    "                                  hyperparameter_tune_kwargs=hyperparameter_tune_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_new_hpo.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to set all negative values to zero\n",
    "predictions_new_hpo = predictor_new_hpo.predict(test)\n",
    "predictions_new_hpo.iloc[predictions_new_hpo.lt(0)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same submitting predictions\n",
    "submission_new_hpo = pd.read_csv('sampleSubmission.csv', parse_dates=[\"datetime\"])\n",
    "submission_new_hpo[\"count\"] = predictions_new_hpo\n",
    "submission_new_hpo.to_csv(\"submission_new_hpo.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c bike-sharing-demand -f submission_new_hpo.csv -m \"new features with hyperparameters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submissions -c bike-sharing-demand | tail -n +1 | head -n 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Score of 0.53050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pd.DataFrame(\n",
    "    {\n",
    "        \"model\": [\"initial\", \"add_features\", \"hpo\"],\n",
    "        \"score\": [\n",
    "            predictor.leaderboard(silent=True)['score_val'][0],\n",
    "            predictor_new_features.leaderboard(silent=True)['score_val'][0],\n",
    "            predictor_new_hpo.leaderboard(silent=True)['score_val'][0]\n",
    "        ]\n",
    "    }\n",
    ").plot(x=\"model\", y=\"score\", figsize=(8, 6)).get_figure()\n",
    "fig.savefig('img/model_train_score.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"model\": [\"initial\", \"add_features\", \"hpo\"],\n",
    "        \"score\": [\n",
    "            predictor.leaderboard(silent=True)['score_val'][0],\n",
    "            predictor_new_features.leaderboard(silent=True)['score_val'][0],\n",
    "            predictor_new_hpo.leaderboard(silent=True)['score_val'][0]\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the 3 kaggle scores and creating a line plot to show improvement\n",
    "fig = pd.DataFrame(\n",
    "    {\n",
    "        \"test_eval\": [\"initial\", \"add_features\", \"hpo\"],\n",
    "        \"score\": [\n",
    "            predictor.leaderboard(silent=True)['score_val'][0],\n",
    "            predictor_new_features.leaderboard(silent=True)['score_val'][0],\n",
    "            predictor_new_hpo.leaderboard(silent=True)['score_val'][0]\n",
    "        ]\n",
    "    }\n",
    ").plot(x=\"test_eval\", y=\"score\", figsize=(8, 6)).get_figure()\n",
    "fig.savefig('img/model_test_score.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The 3 hyperparameters we tuned with the kaggle score as the result\n",
    "pd.DataFrame({\n",
    "    \"model\": [\"initial\", \"add_features\", \"hpo\"],\n",
    "    \"score\": [\n",
    "            predictor.leaderboard(silent=True)['score_val'][0],\n",
    "            predictor_new_features.leaderboard(silent=True)['score_val'][0],\n",
    "            predictor_new_hpo.leaderboard(silent=True)['score_val'][0]\n",
    "        ]\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (MXNet 1.9 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/mxnet-1.9-cpu-py38-ubuntu20.04-sagemaker-v1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
